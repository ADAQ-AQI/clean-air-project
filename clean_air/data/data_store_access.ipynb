{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing the Clean Air Framework Datastore\n",
    "\n",
    "Data is stored on an object store on the JASMIN cloud.\n",
    "Access is encapsulated by a `S3FSDataSetStore` class.\n",
    "(`s3fs` is the underlying library used to access the object store)\n",
    "\n",
    "<details>\n",
    "<summary>\n",
    "    Developer Note: s3fs vs s3fs-fuse\n",
    "</summary>\n",
    "\n",
    "[s3fs](https://pypi.org/project/s3fs/) is a python library that provides a filesystem-like interface,\n",
    "but actually just uses the S3 APIs under the hood and doesn't interact with the local filesystem\n",
    "\n",
    "[s3fs-fuse](https://github.com/s3fs-fuse/s3fs-fuse) actually mounts an S3 compatible bucket as a virtual filesystem,\n",
    "which can be accessed using any method that works for local files.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Credentials\n",
    "Anonymous access is enabled for the data bucket, but to be able to upload data credentials with write permissions are \n",
    "required.\n",
    "\n",
    "Documentation on `s3fs`'s credentials are here: https://s3fs.readthedocs.io/en/latest/#credentials\n",
    "As it uses Amazon AWS's `botocore` library, the credential config is the same as for `botocore` & `boto3`.\n",
    "\n",
    "In summary, the options are (in order of increasing precedence):\n",
    "\n",
    "* `~/.aws/credentials` file (refer to [Configuration and credential file settings](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html)) \n",
    "with contents such as:\n",
    "```\n",
    "[default]\n",
    "aws_access_key_id=AKIAIOSFODNN7EXAMPLE\n",
    "aws_secret_access_key=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n",
    "```\n",
    "* Setting the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` environment variables\n",
    "* Explicitly creating an `s3fs.S3FileSystem` instance and passing them as arguments (refer to next section for details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating a DataSetStore\n",
    "The simplest way to get a valid `DataSetStore` instance is to the use the convenience method `create_dataset_store`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from clean_air.data.storage import create_dataset_store\n",
    "\n",
    "dataset_store = create_dataset_store(storage_bucket_name=\"test-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function supports several parameters that are used to customise the resulting `DataSetStore`:\n",
    "\n",
    "| Parameter Name        | Description | Default |\n",
    "| --------------------- | ----------- | ------- |\n",
    "| `storage_bucket_name` | Name of the bucket where datasets are stored | `caf-data` |\n",
    "| `local_storage_path`  | Path to a writeable directory to store local copies of dataset files | A temporary directory in the systems `tmp` folder |\n",
    "| `endpoint_url`        | the object store service endpoint URL. Changes depending on whether accessing data from inside or outside JASMIN, or using data stored on another AWS S3 compatible object store | `clean_air.data.storage.JasminEndpointUrls.EXTERNAL` |\n",
    "| `anon`                | Whether to use anonymous access or credentials. `anon=False` is required for write access | `True` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Advanced options\n",
    "The helper function creates a `DataSetStore` in its most common configurations, but for more control you can create an \n",
    "instance by using the constructor directly and providing the required arguments.\n",
    "\n",
    "Here's an example of how to pass in credentials programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "from clean_air.data.storage import JasminEndpointUrls\n",
    "from clean_air.data.storage import S3FSDataSetStore\n",
    "\n",
    "fs = s3fs.S3FileSystem(\n",
    "    key=\"AKIAIOSFODNN7EXAMPLE\",\n",
    "    secret=\"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\",\n",
    "    client_kwargs={\"endpoint_url\": JasminEndpointUrls.EXTERNAL})\n",
    "dataset_store_with_custom_credentials = S3FSDataSetStore(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Uploading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "from clean_air.models import MetaData, DataSet\n",
    "\n",
    "# Credentials will need to be configured correctly for this to work\n",
    "dataset_store_with_write_access = create_dataset_store(\"test-data\", anon=False)\n",
    "with tempfile.TemporaryDirectory() as data_dir_path:\n",
    "    # Create some test data\n",
    "    test_datafile = Path(data_dir_path + \"/testfile.txt\")\n",
    "    test_datafile.touch()\n",
    "    metadata = MetaData(dataset_name=\"TestDataSet\")\n",
    "    test_dataset = DataSet(files=[test_datafile], metadata=metadata)\n",
    "\n",
    "    # Upload it\n",
    "    dataset_store_with_write_access.put(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Discovering Data\n",
    "List the names of available datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['TestDataSet']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_store.available_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Downloading Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DataSet(files=[PosixPath('/var/tmp/tmp60yvm1n0/TestDataSet/testfile.txt')], metadata=MetaData(dataset_name='TestDataSet'))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset_store.get(\"TestDataSet\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deployment\n",
    "For read-only/anonmous access to work correctly, the data storage bucket must have this policy applied:\n",
    "```json\n",
    "{\"Version\": \"2008-10-17\",\n",
    " \"Id\": \"Read Access For Anonymous Users\",\n",
    " \"Statement\": [\n",
    "    {\n",
    "      \"Sid\": \"Read-only and list bucket access for Everyone\",\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\"anonymous\": [\"*\"]},\n",
    "      \"Resource\": \"*\",\n",
    "      \"Action\": [\"GetObject\", \"ListBucket\"]\n",
    "    }\n",
    "]\n",
    "}\n",
    "```\n",
    "Note, this policy was written for and tested with the JASMIN object store, so may need tweaking for use with\n",
    "other object stores."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}